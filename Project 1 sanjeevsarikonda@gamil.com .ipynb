{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import translate\n",
    "import pyspark.sql.functions as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-1-1-204.ap-south-1.compute.internal:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Market Analysis in Banking Domain</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0efd0429d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"Market Analysis in Banking Domain\").master(\"yarn\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data and create a Spark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
      "| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
      "| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
      "| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"delimiter\",';').option(\"inferSchema\",True).option(\"header\",True).load(\"Project 1_dataset_bank-full (2).csv\")\n",
    "df = df.withColumn('age', split(df['\"age;\"\"job\"\"'], ';').getItem(0)).withColumn('job', split(df['\"age;\"\"job\"\"'], ';').getItem(1))\n",
    "df = df.select([F.col(col).alias(re.sub('\"\"',\"\",col)) for col in df.columns])\n",
    "df = df.withColumnRenamed('y\"',\"y\")\n",
    "df = df.drop('\"age;job')\n",
    "df = df.select(['age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','y'])\n",
    "df = df.withColumn(\"age\",translate(\"age\",'\"','')).withColumn(\"job\",translate(\"job\",'\"','')).withColumn(\"marital\",translate(\"marital\",'\"','')).withColumn(\"education\",translate(\"education\",'\"','')).withColumn(\"default\",translate(\"default\",'\"','')).withColumn(\"housing\",translate(\"housing\",'\"','')).withColumn(\"loan\",translate(\"loan\",'\"','')).withColumn(\"contact\",translate(\"contact\",'\"','')).withColumn(\"month\",translate(\"month\",'\"','')).withColumn(\"poutcome\",translate(\"poutcome\",'\"','')).withColumn('y',translate('y','\"',''))\n",
    "df = df.withColumn(\"age\",col(\"age\").cast(\"Integer\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataFrame into Sql dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"bank\")\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Give marketing success rate (No. of people subscribed / total no. of entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           success|\n",
      "+------------------+\n",
      "|11.698480458295547|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select (a.sub/b.tot)*100 as success from (select count(*) as sub from bank where  y='yes') a,(select count(*) as tot from bank) b\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Give the maximum, mean, and minimum age of the average targeted customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|Maximum_Targeted_Age|Average_Targeted_Age|Minimum_Targeted_Age|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                  95|   40.93621021432837|                  18|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT MAX(age) as Maximum_Targeted_Age, AVG(age) as Average_Targeted_Age,MIN(age) as Minimum_Targeted_Age FROM bank').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check the quality of customers by checking average balance, median balance of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+\n",
      "|   Average_Balance|Median_balance|\n",
      "+------------------+--------------+\n",
      "|1362.2720576850766|           448|\n",
      "+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT AVG(balance) as Average_Balance, percentile_approx(balance, 0.5) as Median_balance FROM bank').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check if age matters in marketing subscription for deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|number|\n",
      "+---+------+\n",
      "| 32|  1864|\n",
      "| 31|  1790|\n",
      "| 33|  1762|\n",
      "| 34|  1732|\n",
      "| 35|  1685|\n",
      "| 36|  1611|\n",
      "| 30|  1540|\n",
      "| 37|  1526|\n",
      "| 39|  1344|\n",
      "| 38|  1322|\n",
      "| 40|  1239|\n",
      "| 41|  1171|\n",
      "| 42|  1131|\n",
      "| 45|  1110|\n",
      "| 43|  1058|\n",
      "| 46|  1057|\n",
      "| 44|  1043|\n",
      "| 29|  1014|\n",
      "| 47|   975|\n",
      "| 48|   915|\n",
      "+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select age, count(*) as number from bank where  y ='no' group by age order by number desc \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check if marital status mattered for a subscription to deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "| marital|number|\n",
      "+--------+------+\n",
      "| married| 24459|\n",
      "|  single| 10878|\n",
      "|divorced|  4585|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select marital, count(*) as number from bank where  y ='no' group by marital order by number desc \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check if age and marital status together mattered for a subscription to deposit scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+\n",
      "|age|marital|number|\n",
      "+---+-------+------+\n",
      "| 34|married|  1013|\n",
      "| 33|married|   978|\n",
      "| 35|married|   976|\n",
      "| 36|married|   976|\n",
      "| 37|married|   975|\n",
      "| 32|married|   920|\n",
      "| 31| single|   906|\n",
      "| 39|married|   873|\n",
      "| 30| single|   861|\n",
      "| 40|married|   856|\n",
      "| 45|married|   825|\n",
      "| 38|married|   819|\n",
      "| 32| single|   817|\n",
      "| 41|married|   803|\n",
      "| 31|married|   801|\n",
      "| 46|married|   772|\n",
      "| 42|married|   770|\n",
      "| 43|married|   743|\n",
      "| 47|married|   743|\n",
      "| 44|married|   734|\n",
      "+---+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select age, marital, count(*) as number from bank where y='no' group by age,marital order by number desc \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do feature engineering for the bank and find the right age effect on the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+\n",
      "|age_cat|  y|count|\n",
      "+-------+---+-----+\n",
      "|    Mid| no|35146|\n",
      "|  Young|yes|  928|\n",
      "|  Young| no| 4345|\n",
      "|    Mid|yes| 4041|\n",
      "|    Old|yes|  320|\n",
      "|    Old| no|  431|\n",
      "+-------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= df.withColumn(\"age_cat\", when(df.age >65 ,\"Old\")\n",
    "                                 .when(df.age <30,\"Young\")\n",
    "                        .otherwise(\"Mid\"))\n",
    "df.groupBy(\"age_cat\",\"y\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
